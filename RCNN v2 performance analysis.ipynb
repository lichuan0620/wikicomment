{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will test a improved RCNN model. It utlizies several new tools that might improve the model's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXsRFoKJSNrH"
   },
   "source": [
    "# 1. Preparation\n",
    "We need to first import the required library, download the data, and load the data into the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "swLpnk4u4XKo"
   },
   "source": [
    "## 1.1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 394,
     "output_extras": [
      {
       "item_id": 5
      },
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4509,
     "status": "ok",
     "timestamp": 1518570583550,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "9_NbEq2FSFLe",
    "outputId": "58bb96d9-3ffa-4ccf-b90a-c2db87f537b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing required packages...\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ChuanLi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ChuanLi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "print('Importing required packages...')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed()\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing import text as ktxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, SpatialDropout1D, Bidirectional, Dropout\n",
    "from keras.layers import Concatenate, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "def hint(message):\n",
    "    \"\"\"\n",
    "    erase previous ipynb output and show new message\n",
    "    \"\"\"\n",
    "    clear_output()\n",
    "    print(message)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0oMhFbcOS7ch"
   },
   "source": [
    "## 1.2 Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 153,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1518570590592,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "C1nwDbfiS-vX",
    "outputId": "d69716f3-d89c-49a1-91d3-7cfe42286b4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution between training and validation set:\n",
      "           label     train  validation\n",
      "0          toxic  0.095906    0.095598\n",
      "1   severe_toxic  0.009949    0.010183\n",
      "2        obscene  0.053151    0.052138\n",
      "3         threat  0.003024    0.002883\n",
      "4         insult  0.049344    0.049444\n",
      "5  identity_hate  0.009032    0.007896\n"
     ]
    }
   ],
   "source": [
    "hint('loading data...')\n",
    "train = pd.read_csv('data/train.csv')\n",
    "train, valid = train_test_split(train, test_size=0.2)\n",
    "\n",
    "labels = [\n",
    "    'toxic', \n",
    "    'severe_toxic', \n",
    "    'obscene', \n",
    "    'threat', \n",
    "    'insult', \n",
    "    'identity_hate'\n",
    "]\n",
    "\n",
    "Ytr = train[labels].values\n",
    "Yva = valid[labels].values\n",
    "\n",
    "hint('Label distribution between training and validation set:')\n",
    "print(pd.DataFrame({\n",
    "    'label': labels,\n",
    "    'train': [np.mean(train[label]) for label in labels],\n",
    "    'validation' : [np.mean(valid[label]) for label in labels],\n",
    "}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KA8OAJOJWAoe"
   },
   "source": [
    "# 2. Pre-processing the Input\n",
    "There are many ways to pre-process the raw strings into valid input for the model. Here we will do it by building a dictionary with all the comments from the training set, mapping the words to their index in the dictionary, and pad/crop the resulting sequences so that they have the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmEOAxm4wdNn"
   },
   "source": [
    "## 2.1 Cleaning Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1518570683382,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "Q5jQUn7MxSud",
    "outputId": "73b337ab-1654-422d-cad2-a82158bd8880"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "tkzr = TweetTokenizer(preserve_case=False)\n",
    "eng_stopwords = (\n",
    "    'what', 'which', 'who', 'whom', \n",
    "    'this', 'that', 'these', 'those', \n",
    "    'am', 'is', 'are', 'was', 'were', \n",
    "    'be', 'been', 'being', \n",
    "    'have', 'has', 'had', 'having', \n",
    "    'do', 'does', 'did', 'doing', \n",
    "    'a', 'an', 'the', \n",
    "    'and', 'but', 'if', 'or', \n",
    "    'because', 'as', 'until', 'while', \n",
    "    'of', 'at', 'by', 'for', 'with', \n",
    "    'about', 'against', 'between', \n",
    "    'into', 'through', 'during', 'before', 'after', \n",
    "    'above', 'below', 'to', 'from', \n",
    "    'up', 'down', 'in', 'out', 'on', 'off', \n",
    "    'over', 'under', 'again', 'further', \n",
    "    'then', 'once', 'here', \n",
    "    'there', 'when', 'where', 'why', \n",
    "    'how', 'all', 'any', 'both', 'each', \n",
    "    'few', 'more', 'most', 'other', 'some', \n",
    "    'such', 'no', 'nor', 'not', 'only', \n",
    "    'own', 'same', 'so', 'than', 'too', 'very', \n",
    "    'can', 'will', 'just', 'don', 'should', 'now'\n",
    ")\n",
    "lmtzr = WordNetLemmatizer()\n",
    "appos = {\n",
    "    \"aren't\" : \"are not\",\n",
    "    \"can't\" : \"cannot\",\n",
    "    \"couldn't\" : \"could not\",\n",
    "    \"didn't\" : \"did not\",\n",
    "    \"doesn't\" : \"does not\",\n",
    "    \"don't\" : \"do not\",\n",
    "    \"hadn't\" : \"had not\",\n",
    "    \"hasn't\" : \"has not\",\n",
    "    \"haven't\" : \"have not\",\n",
    "    \"he'd\" : \"he would\",\n",
    "    \"he'll\" : \"he will\",\n",
    "    \"he's\" : \"he is\",\n",
    "    \"i'd\" : \"I would\",\n",
    "    \"i'd\" : \"I had\",\n",
    "    \"i'll\" : \"I will\",\n",
    "    \"i'm\" : \"I am\",\n",
    "    \"isn't\" : \"is not\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"it'll\":\"it will\",\n",
    "    \"i've\" : \"I have\",\n",
    "    \"let's\" : \"let us\",\n",
    "    \"mightn't\" : \"might not\",\n",
    "    \"mustn't\" : \"must not\",\n",
    "    \"shan't\" : \"shall not\",\n",
    "    \"she'd\" : \"she would\",\n",
    "    \"she'll\" : \"she will\",\n",
    "    \"she's\" : \"she is\",\n",
    "    \"shouldn't\" : \"should not\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"there's\" : \"there is\",\n",
    "    \"they'd\" : \"they would\",\n",
    "    \"they'll\" : \"they will\",\n",
    "    \"they're\" : \"they are\",\n",
    "    \"they've\" : \"they have\",\n",
    "    \"we'd\" : \"we would\",\n",
    "    \"we're\" : \"we are\",\n",
    "    \"weren't\" : \"were not\",\n",
    "    \"we've\" : \"we have\",\n",
    "    \"what'll\" : \"what will\",\n",
    "    \"what're\" : \"what are\",\n",
    "    \"what's\" : \"what is\",\n",
    "    \"what've\" : \"what have\",\n",
    "    \"where's\" : \"where is\",\n",
    "    \"who'd\" : \"who would\",\n",
    "    \"who'll\" : \"who will\",\n",
    "    \"who're\" : \"who are\",\n",
    "    \"who's\" : \"who is\",\n",
    "    \"who've\" : \"who have\",\n",
    "    \"won't\" : \"will not\",\n",
    "    \"wouldn't\" : \"would not\",\n",
    "    \"you'd\" : \"you would\",\n",
    "    \"you'll\" : \"you will\",\n",
    "    \"you're\" : \"you are\",\n",
    "    \"you've\" : \"you have\",\n",
    "    \"'re\": \" are\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'll\":\" will\",\n",
    "    \"didn't\": \"did not\"\n",
    "}\n",
    "\n",
    "def preprocess(comment):\n",
    "  \n",
    "    # credit to the author of this post:\n",
    "    # https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda\n",
    "\n",
    "    # remove special format\n",
    "    comment = re.sub('\\n\\t', '', comment)\n",
    "\n",
    "    # remove IP addresses\n",
    "    comment = re.sub('\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' specipaddress ', comment)\n",
    "\n",
    "    # remove username\n",
    "    comment = re.sub(\"\\[\\[User.*\\]\", ' specusername ', comment)\n",
    "    comment = re.sub(\"\\[\\[User.*\\|\", ' specusername ', comment)\n",
    "\n",
    "    # tokenization \n",
    "    tokens = tkzr.tokenize(comment)\n",
    "\n",
    "    # aphostophe replacement\n",
    "    tokens = [ appos[token] if token in appos else token for token in tokens]\n",
    "\n",
    "    # remove stopwords\n",
    "    tokens = [ token for token in tokens if not token in eng_stopwords ]\n",
    "\n",
    "    # stemming\n",
    "    tokens = [ lmtzr.lemmatize(token, 'v') for token in tokens]\n",
    "\n",
    "    return \" \".join(tokens)\n",
    "  \n",
    "\n",
    "hint('Cleaning train set...')\n",
    "Xtr = train['comment_text'].apply(lambda c: preprocess(c))\n",
    "hint('Cleaning test set...')\n",
    "Xva = valid['comment_text'].apply(lambda c: preprocess(c))\n",
    "hint('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "btLphIdFwmts"
   },
   "source": [
    "## 2.2 Transforming Comments to Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 144,
     "status": "ok",
     "timestamp": 1518570698059,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "JmEQQZs-kHK2",
    "outputId": "073af561-39f5-4c18-acee-ab2794e9e3a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "vocab_max = 100000\n",
    "\n",
    "hint('Fitting the tokenizer...')\n",
    "tokenizer = ktxt.Tokenizer(num_words=vocab_max)\n",
    "tokenizer.fit_on_texts(Xtr)\n",
    "\n",
    "hint('Tokenizing...')\n",
    "Xtr = tokenizer.texts_to_sequences(Xtr)\n",
    "Xva = tokenizer.texts_to_sequences(Xva)\n",
    "\n",
    "hint('padding the sequences...')\n",
    "max_comment_length = 200  # padded/cropped comment length\n",
    "Xtr = sequence.pad_sequences(Xtr, maxlen=max_comment_length)\n",
    "Xva = sequence.pad_sequences(Xva, maxlen=max_comment_length)\n",
    "\n",
    "hint('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OWHeGxuz3Wfn"
   },
   "source": [
    "# 3. Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hint(\"Loading pre-embedding file...\")\n",
    "emb = pd.read_table(\n",
    "    'preembedding/glove.840B.300d.txt', \n",
    "    sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE\n",
    ")\n",
    "\n",
    "hint(\"Preparing embedding matrix...\")\n",
    "embedding_dimension = 300\n",
    "embedding_matrix = np.random.normal(\n",
    "    emb.mean(axis=0), \n",
    "    emb.std(axis=0), \n",
    "    (vocab_max, embedding_dimension)\n",
    ")\n",
    "hint(\"Constructing embedding matrix\")\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < vocab_max and word in emb.index:\n",
    "        embedding_matrix[i] = emb.loc[word].as_matrix()\n",
    "\n",
    "hint(\"Done\")\n",
    "# optional: free memory:\n",
    "emb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 374,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1518570698678,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "GoawhjBA3nyc",
    "outputId": "e814cec6-a98e-4cce-da53-d2579963c70f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 200, 300)          30000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 200, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 200, 256)          230656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_2 (Spatial (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          123264    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 30,354,694\n",
      "Trainable params: 30,354,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = None\n",
    "model = Sequential()\n",
    "model.add(Embedding(\n",
    "    vocab_max, \n",
    "    embedding_dimension, \n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_comment_length\n",
    "))\n",
    "model.add(SpatialDropout1D(0.5))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(Bidirectional(GRU(units=64, return_sequences=True)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "#model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(labels), activation='sigmoid'))\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1S6kDCqDFGUN"
   },
   "source": [
    "Now training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 122,
     "output_extras": [
      {
       "item_id": 373
      },
      {
       "item_id": 1155
      },
      {
       "item_id": 1418
      },
      {
       "item_id": 2339
      },
      {
       "item_id": 2340
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 630277,
     "status": "ok",
     "timestamp": 1518571329571,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "QVU9nuDzFtlf",
    "outputId": "e0ea2b97-fe62-42bf-a1b2-46c7d5f08532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/2\n",
      "127656/127656 [==============================] - 332s 3ms/step - loss: 0.1391 - acc: 0.9799 - val_loss: 0.0435 - val_acc: 0.9832\n",
      "Epoch 2/2\n",
      "127656/127656 [==============================] - 327s 3ms/step - loss: 0.1063 - acc: 0.9837 - val_loss: 0.0422 - val_acc: 0.9837\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 64\n",
    "\n",
    "def get_class_weight(x):\n",
    "    k = 100\n",
    "    return 3.32*np.log(k/x + 1)\n",
    "    \n",
    "\n",
    "history = model.fit(\n",
    "    Xtr, Ytr, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size,\n",
    "    validation_data=(Xva, Yva),\n",
    "    class_weight={\n",
    "        0: get_class_weight(98),\n",
    "        1: get_class_weight(10),\n",
    "        2: get_class_weight(53),\n",
    "        3: get_class_weight(2),\n",
    "        4: get_class_weight(49),\n",
    "        5: get_class_weight(8),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAFiq9QuFI7R"
   },
   "source": [
    "Making prediction on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1518571356080,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "hgiIMLjZE3Rr",
    "outputId": "f00c0add-a7ab-43f7-b75d-c47a54e12890"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "hint(\"Making prediction...\")\n",
    "Yva_ = model.predict(Xva)\n",
    "hint(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RfRNkLv7v04I"
   },
   "source": [
    "# 4. Result Analysis\n",
    "## 4.1 Global Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 255,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1518571356419,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "vakvDUO31-oo",
    "outputId": "5b7acf10-a987-41f7-801c-0f291245b687"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation set sample count: 31915\n",
      "\n",
      "accuracy for threshold 0.1: 97.19%\n",
      "accuracy for threshold 0.2: 97.89%\n",
      "accuracy for threshold 0.3: 98.16%\n",
      "accuracy for threshold 0.4: 98.30%\n",
      "accuracy for threshold 0.5: 98.37%\n",
      "accuracy for threshold 0.6: 98.32%\n",
      "accuracy for threshold 0.7: 98.24%\n",
      "accuracy for threshold 0.8: 98.07%\n",
      "accuracy for threshold 0.9: 97.66%\n",
      "\n",
      "best threshold: 0.5\n",
      "best accuracy: 98.37%\n"
     ]
    }
   ],
   "source": [
    "total_sample = Xva.shape[0]\n",
    "print(\"validation set sample count: %d\\n\" % total_sample)\n",
    "prediction_total = total_sample*Yva.shape[1]\n",
    "best_t = None\n",
    "best_accuracy = 0\n",
    "for t in [i*0.1 for i in range(1, 10)]:\n",
    "    accuracy = np.sum(Yva == (Yva_ >= t))/prediction_total\n",
    "    if accuracy > best_accuracy: \n",
    "        best_t = t\n",
    "        best_accuracy = accuracy\n",
    "    print(\"accuracy for threshold %.1f: %.2f%%\" % (t, accuracy*100))\n",
    "Yva_T = Yva_ >= best_t\n",
    "correct = Yva == Yva_T\n",
    "print(\"\\nbest threshold: %.1f\" % best_t)\n",
    "print(\"best accuracy: %.2f%%\" % (best_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSptfDNc58dZ"
   },
   "source": [
    "## 4.2 Accuracy by Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gLRH9AayowXA"
   },
   "outputs": [],
   "source": [
    "overview = pd.DataFrame(index=[\n",
    "    'label‰ of all',\n",
    "    'total wrong', \n",
    "    'P->N', \n",
    "    'N->P', \n",
    "    'P->N %', \n",
    "    'N->P %',\n",
    "    'avg len',\n",
    "])\n",
    "\n",
    "def analyze_class(i):\n",
    "    wrong = valid[correct[:, i] != 1]\n",
    "    total_class_error = len(wrong)\n",
    "    print(\"%d predicted incorrectly (%.2f%% of all samples)\" % (\n",
    "        total_class_error, \n",
    "        100*total_class_error/total_sample\n",
    "    ))\n",
    "        \n",
    "    wrong_seqs = Xva[correct[:, i] != 1]\n",
    "    lens = [ len(seq[seq != 0]) for seq in wrong_seqs]\n",
    "    avg_len = np.mean(lens)\n",
    "    print(\"Falsely predicted sequences have an average length of %d\" % avg_len)\n",
    "\n",
    "    PpN = valid[(Yva[:, i] == 1) & (Yva_T[:, i] == 0)]\n",
    "    PpN_count = len(PpN)\n",
    "    print(\"\\n%d (%.2f%%) positive label were predicted to be negative\" % (\n",
    "        PpN_count, \n",
    "        100*PpN_count/total_class_error \n",
    "    ))\n",
    "    if PpN_count > 4:\n",
    "        print(\"Samples:\")\n",
    "        for sample in PpN.sample(5)['comment_text']:\n",
    "            display(sample)\n",
    "  \n",
    "    NpP = valid[(Yva[:, i] == 0) & (Yva_T[:, i] == 1)]\n",
    "    NpP_count = len(NpP)\n",
    "    print(\"\\n%d (%.2f%%) negative label were predicted to be positive\" % (\n",
    "        NpP_count, \n",
    "        100*NpP_count/total_class_error \n",
    "    ))\n",
    "    if NpP_count > 4:\n",
    "        print(\"Samples:\")\n",
    "        for sample in NpP.sample(5)['comment_text']:\n",
    "            display(sample)\n",
    "  \n",
    "    overview[labels[i]] = [\n",
    "        np.mean(Yva[:, i]*1000),\n",
    "        total_class_error, \n",
    "        PpN_count,  \n",
    "        NpP_count,\n",
    "        100*PpN_count/total_class_error,\n",
    "        100*NpP_count/total_class_error,\n",
    "        avg_len\n",
    "    ]\n",
    "  \n",
    "    print('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSY9H7knpE5U"
   },
   "source": [
    "### 4.2.1 Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 360,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      },
      {
       "item_id": 8
      },
      {
       "item_id": 9
      },
      {
       "item_id": 10
      },
      {
       "item_id": 11
      },
      {
       "item_id": 12
      },
      {
       "item_id": 13
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 251,
     "status": "ok",
     "timestamp": 1518573461778,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "NNGw690DpLMy",
    "outputId": "18e4b55e-63d1-42b2-9c93-4b75a8d5ad39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1134 predicted incorrectly (3.55% of all samples)\n",
      "Falsely predicted sequences have an average length of 35\n",
      "\n",
      "850 (74.96%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Prediction Timetable is getting bloated \\n\\nWhy do you people have to add EVERY FREAKING DETAIL to the list? It needs to be kept simple and not as wordy, this is a wikipedia article not a damn novel. If you wanna know all the details WATCH THE DAMN SHOW – IT'S FREE ON GOOGLE VIDEOS! The list should only contain the most notable and important details. A lot of what is there isn't all that notable – Do we need to know the name of every stupid bridge and building shown collapsing or can we just say – a bunch of bridges and buildings collapsed here and mention ONE OR TWO by name as examples. I don't want to get involved in edit wars but I will delete things I believe are overly worded, redundant and unnecessary, and not to mention just stupid. Use common sense before you edit.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I'm not new. I don't know what the hell you are talking about.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Well i think that is just plain stupid..i have seen retarted things on this site, i actually put together a nice little thing for him with ppl editing it. He is a good teacher and a great local wrestler with a bright carrear in front of him, and i dont see wh yu wont have him on this, all i know is he is my personal hero and i think people should know about him and some of the things he does i.e the wrestling moves he does etc.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'OMG!!! someone is making threats...iam so scared.. thats funny you change and make up your own barnstars thats low and embarassing!! Get a life!! like one out of this site!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'. Start your hostile attacks now, Pgagnon999'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "284 (25.04%) negative label were predicted to be positive\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Strange that. It seemed like you were perfectly willing to engage in debate about what the evidence showed about the crash site until I started asking you simple physical questions like 'if the wings sheared off, how did they get in the building?','why would the wings shear off when they would have applied far more force than the stress bearing capacity of a concrete wall?', 'why weren't there any burn marks on the lawn?', and (for fuck sake) 'small hole, big plane, how does that work in a physical sense ?(with more sophisticated details than 'they were blown to hell and back')'. I asked these questions because the answers to them are vital for impartial users of the site to make an informed decision. I added photographs and measurements (and only these things, without conspiracy fairy stories) to help people do this. Instead of constructively discussing what aspects of the measurements were right and wrong and why, or helping me find the copyright details of the photographs (which I believe editors of wikipedia are supposed to do), you just delete my edit without any justification other than 'its conspiratorial, therefore false'.\\n\\nI know you're not 'agents of the US government' or some crap. You're just ignornant of physics, or deliberately being narrow-minded because the (fucking obvious) truth makes you uncomfortable. A lie told a thousand times becomes the truth. So congratulations. Thanks to your efforts, the lie that a 757 hit the pentagon on 11/09/01 is well on the way to becoming true. You stupid, stupid bastards.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'YOUR UNDER ARREST \\n\\nMA NAME IS DI TYLER AND YOUR UNDERARREST BOI'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dictatorship \\n\\ngot a pic of hitler above the mantel????'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'yopu smell like fish'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n Possibly Twins? \\n\\nYou are WillowW and I am PillowP. Perhaps we are separated twins! \\n\\nWe seem to have so many things in common. I, too, sit around and drool at the computer for hours, furiously editing useless articles about math. And hey, I also have a mediocre knowledge of latin poetry! \\n\\nMaybe we can get together and feel better than other people because we patrol Wikipedia. Gee, but I look up to you. I wish I had a picture of a statue of a little girl holding a dead bird. (. I\\'m pouting! \\n\\n  The Special Editor because you have been extraordinarily slow with the people who have left comments at your Retardation Featured list, taking the time to drool on every single reviewer.  \\n\\nI\\'m a person just like you\\nBut I\\'ve got better things to do\\nThan sit around and fuck my head\\nHang out with the living dead\\nSnort white shit up my nose\\nPass out at the shows\\nI don\\'t even think about speed\\nThat\\'s something I just don\\'t need\\n\\nI\\'ve got the straight edge\\n\\n   \\n\\np.s. WillowW is a STUPID name. period blood.\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3cxSNKFepEg1"
   },
   "source": [
    "### 4.2.2 Severe Toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 360,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      },
      {
       "item_id": 8
      },
      {
       "item_id": 9
      },
      {
       "item_id": 10
      },
      {
       "item_id": 11
      },
      {
       "item_id": 12
      },
      {
       "item_id": 13
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1518573463811,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "1cCGMbZKpV1H",
    "outputId": "428d69ea-64a9-4f28-e09c-f9ddd6d7516c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 predicted incorrectly (0.94% of all samples)\n",
      "Falsely predicted sequences have an average length of 25\n",
      "\n",
      "219 (73.00%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You and Jack greenmaven are MotherFuckers'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Hello all!  I have been blocked by these assholes for speaking my mind.  Wikipedia and their liberal minions can suck my fucking dick.  No funds from me and I'll see that nobody I know contributes.  Fuck OFF!!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\n good job for sucking dick \\n\\n  dick trophy i dont have to do shit u say . and ur the worlds best dick sucker   \"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fuck you \\n\\nfuck you deletionist.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURITYFUCK HOMELAND SECURI'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "81 (27.00%) negative label were predicted to be positive\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FUCK U! \\n\\nI AINT G0TTA DO SHIT AND FUCK WIKIPEDIA YALL WEAK MOTHER FUCKERS GET UR INFO RIGHT AND LOCK ALL UR SHIT CUZ YOUR INFO IS ALL WRONG SO SUCK MY DICK AND FUCK U BITCH AND MIND UR BUSINESS OR U CAN SUCK MY DICK OR KISS MY ASS!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'your fucking face. faggots'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'your a fag suck a dick monky nigger lover.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'BULLSHIT Bullshit \\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit\\nBULLSHIT Bullshit'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Suitecivil your a pussy ass bitch i'd fucken kick your ass any fucken day you little bitch face cunt fuck you and fuck barcelona.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0_zIe7m1A79"
   },
   "source": [
    "### 4.2.3 Obscene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 360,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      },
      {
       "item_id": 8
      },
      {
       "item_id": 9
      },
      {
       "item_id": 10
      },
      {
       "item_id": 11
      },
      {
       "item_id": 12
      },
      {
       "item_id": 13
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1518573465290,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "Qt9vOoNK1EFl",
    "outputId": "cfeec26f-71ad-4668-840e-c183a862ba74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571 predicted incorrectly (1.79% of all samples)\n",
      "Falsely predicted sequences have an average length of 38\n",
      "\n",
      "257 (45.01%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nI\\'m wondering whether to add the fact to the article that she recently received a bukkake from five black dudes and the video was uploaded to slutload.com. She was first face f*ucked. I\\'m not sure if it\\'s notable enough to include but it was recent (rather surprising news) and her husband is filing for a divorce after she refused to swallow his sperm. I don\\'t have a definite source for this, unfortunately. If I did, I would add it to the article. Anyone have any references? (BTW, I know it sounds preposterous and I\\'m surprised too but I\\'ve read this in a very reliable source (put in \"\"nicer terms\"\" like \"\"she engaged in sexual acts with african americans\"\").) Thanks guys.\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry I was an asshole about it.  The point is that the vowels in man and noun are raised in AusE according to Felicity Cox (2005), and the phonetic transcription for that IDEA example I gave you transcribes man as , and indeed it sounds like that to my ears, although that speaker did seem a bit broad.  It's not that uncommon for vowels to be raised before nasals.  Take for example the pin-pen merger in Southern American English and in southwestern Ireland or the non-phonemic æ-tensing that takes place in accents that have undergone the Northern cities vowel shift.  The only reason I brought this up is because I imagine it is very noticeable to English ears (it's even noticeable to my American ears).  Many English people might pronounce man as , which sounds quite a bit different from .  You're the Aussie here, so I'm sure you can verify this by simply contrasting your man with your bad (in this case both would have a long vowel, so try to listen for the quality of the vowels) or your noun with your loud.  This is just another little thing that distinguishes Aussie English from English English; that's all.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'THERE HASNT BEEN ANY EPISODES SINCE MARCH 7, DUMBASSES!!! \\n\\n50.180.208.181'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I will be perfectly clear:  a man saying another man is interested in male genatalia and children is fighting words (bad english, but the point is there).  You were deliberately rude to me and, frankly you can f*** o**.  Should you have the power with this site to remove/destroy my presence, then you had best: do so; attempt a different tone; leavev me alone.  I herein provide you that opportunity.\\n\\nMy best,\\n\\n Xchanter'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"i hate you computer nerds and if i get blocked please get me blocked by 'cant sleep clown will eat me'. ok thats all ive got to say to u patetic losers who sit in front of a computer all day.\\n\\nBold textFUCK YOU ALL!!!!!!!!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "314 (54.99%) negative label were predicted to be positive\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"This has nothing to do with the article, but I f*ucking love Paul Miller's late show. Just had to say that, lulz sorry.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hello, do you have a real job? Or is your life so F.U that you gain solace from editing wiki all day with your inane drivel? Get a real job that pays!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I shat somethin' out this mornin' prettier than you! \\n\\nI HOPE YOU GET FLUSHED DOWN A TOILET, WHERE YOU BELONG\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Drakhan!  U have no power over mask of life, so knock off peging there admin and let the link alone, it dosn't break the link page rules, so suck it up!\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'you are dumb \\n\\nyou are dumb and stupid loser'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lwpco7aB1GrZ"
   },
   "source": [
    "### 4.2.4 Threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1518573466922,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "gQgcRgOq1GLO",
    "outputId": "69893ed6-1588-41db-eff3-e86766fac8e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89 predicted incorrectly (0.28% of all samples)\n",
      "Falsely predicted sequences have an average length of 27\n",
      "\n",
      "85 (95.51%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'ma smack ya upside da head wit a shovel \\n\\nI'm takin ya down, boi.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\"\\nWow, you\\'re the one commenting on how users commenting on the page are \"\"drooling retards\"\" and you try to drop this courtesy C&P; on me? You\\'re just as pathetic as you\\'ve always been and I hope you die in a jizz fire.\"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'8=====D- - - \\n8=====D- - - -\\n8======D- - -                \\n8=====D- - - \\n8========D- - - \\n8=======D- - - -\\n8=====D- - - - -\\n8=======D- - - -\\n\\nI hope you liberal faggots die and go to hell! Barack Obama 2008!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'I really hate you \\n\\nAnd I want to do nasty things to you'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Go and hang yourself!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4 (4.49%) negative label were predicted to be positive\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6lkRScLJ1fGN"
   },
   "source": [
    "### 4.2.5 Insult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 360,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      },
      {
       "item_id": 8
      },
      {
       "item_id": 9
      },
      {
       "item_id": 10
      },
      {
       "item_id": 11
      },
      {
       "item_id": 12
      },
      {
       "item_id": 13
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 270,
     "status": "ok",
     "timestamp": 1518573480301,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "zJ2VKxgK1hRC",
    "outputId": "68a3f353-831b-426f-85dc-9d65a39561cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799 predicted incorrectly (2.50% of all samples)\n",
      "Falsely predicted sequences have an average length of 28\n",
      "\n",
      "438 (54.82%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\" The \"\"C\"\" isn\\'t just a logogram, like you religiously and idiotically insist it is.  \"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Jaycie\\nIt's not as simple as you put it man! It's not just about some trying to get a reputation! She already is known out there, and read the more detailed one for what I'm trying to get across! FFS! No-one is right deleting it, fuckin' fools!\\nMAZITO - Tuesday, 26 December, 2006; 02:20 (GMT)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Shut up, you button!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"Idiot \\n\\nI just wanted to let you know that you and 5 Albert square are doing an awful job with eastenders characters, full siblings have completely different family layouts than each other, some characters are on a relatives info box and when you click on that character, the character before isn't on their info box!! Just wanted to let you know that you are ruining Wikipedia for everyone else😊that is all.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nhey warrens, fuck you too. \"\"Uncivil manner, means me trying to elaborate on my arguments and getting  revert on revert that\\'s what uncivil means. So yeah your a big winner champ and won\\'t get banned. Asshole. \\n\\nSince the vista article contains information about the anti trust situation which, since it seems some people here have got a mouthful of gate\\'s balls, is mislabelled anti trust controversy. Not really a controversy though is it when a court elected by over two hundred million people issues a decision, it\\'a court ruling, like it or not there\\'s no controversy too that. Otherwise we should renaim the ted bundy trial, to the tend bundy controversy, since any court ruling merits this label. \\n\\nSince there\\'s a section on anti trust laws and vista, it\\'s worth noting the recent news that microsoft are going to be paying a hefty daily fine for completely ignoring the court\\'s injuction. And this does have bearing on vista. You can\\'t quote the m.s. pr saying we don\\'t know what they want us to do, it\\'s all questions, or whatever else he mentioned, without an adjunct sentence, of the head official regulating the anti trust actions quoting him too saying that our injuctions are crystal clear yet ms has ignored them for over two years now. \\n\\nBut of course this has no bearing if this article is supposed to be a showcase for vista.\\n\\nSo like i said, if some fuckers had gone into the trouble of actually discussing any of that instead of reverted every single edit in a hitleric fashion, things would be different.\\n\\nBut for now this stategy of being a hawk on an article I wish to keep in a certain way, and being completely uncivil and rude about it, merits from my part a roayl, fuck y\\'s all, take your mouths off of gate\\'s balls and then we can talk.\\n \"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "361 (45.18%) negative label were predicted to be positive\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Don't be such a pussy \\n\\nlol it's funny how your panties are in a bunch...sad...are you on your period?\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hey Freepsbane, does your mother know that you have been getting fucked by for some time now?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"You had no right to close my request. You are a lying pig. I did nothing wrong and am better than all of you f-ing idiots. You can't add 1 and 1 but I am the smartest person here.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I'm bored of your warning shit.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'All those stupid little blocks will not stop me, I am very patient, I will keep coming back over and over again.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybjmae651jxY"
   },
   "source": [
    "### 4.2.6 Identity Hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "output_extras": [
      {
       "item_id": 1
      },
      {
       "item_id": 2
      },
      {
       "item_id": 3
      },
      {
       "item_id": 4
      },
      {
       "item_id": 5
      },
      {
       "item_id": 6
      },
      {
       "item_id": 7
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 440,
     "status": "ok",
     "timestamp": 1518573482230,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "6ojSnXP51jPm",
    "outputId": "d1ee8ad8-5407-43c8-cab2-a5f77112fa2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235 predicted incorrectly (0.74% of all samples)\n",
      "Falsely predicted sequences have an average length of 29\n",
      "\n",
      "175 (74.47%) positive label were predicted to be negative\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hey \\nFuck you, you Russia-loving cunt.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"You are such a fucking faggot, there's no need for references for something that can't really be reliably cited. Even if there was a sociological study on people who have APD, coke drinkers, and cocaine users, it wouldn't be very reliable because there's no way to tell if people are lying. Fuck off you beaurocratic official peice of pedophile, and that citing and copyright shit has got to go. I refused to make bibliographies in high school for one reason: I never claimed that the work was mine, and I shouldn't have to claim who's it was because it's self-explanitory that I didn't make it since I didn't claim to have done so.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Mate, sound like you are jewish\\n\\nGayness is in the air'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'To the faggot \\n\\nCoffee Expliciton'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\"\\n\\nSupport for that any many more similar statements is ALL OVER the Iranian media, including the ones who are not in line with Ahmadinejad from a political or ideological point of view.  Playing the retarded trick of \"\"bring me a verifiable quote\"\" for every sentence that you don\\'t like or don\\'t want, and even when a quote is provided, deleting it for lame excuses makes you look like, god forbid, a Jew.  Are you a dirty Jew by any chance?   \"'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "60 (25.53%) negative label were predicted to be positive\n",
      "Samples:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your stupid greeting \\n\\nScrew that stupid greeting from you and get lost you nigger!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Ass rape \\n\\nAre you in an ass raping relationship with Splash15hotel? Fag semen and whore feces will eventually choke you!!!!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i live with my mom and im a gay fag that lives in england'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'answer: Gay people like me.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/* Im gay and im Proud */  \\n\\nListen every one i recently came out of the closet and came out as a homosexual and i have just told my parents this ....HOOORRAY BEER!!!!!!!!\\n\\n The VaNdAl'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_class(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GYOBKlWc12Rc"
   },
   "source": [
    "### 4.2.7 Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 235,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1518573484262,
     "user": {
      "displayName": "Chuan Li",
      "photoUrl": "//lh3.googleusercontent.com/-ry1V_A03qTg/AAAAAAAAAAI/AAAAAAAAAh4/Ea41Em8n49A/s50-c-k-no/photo.jpg",
      "userId": "106476928809257656982"
     },
     "user_tz": 480
    },
    "id": "w9g39VJ4n00f",
    "outputId": "8e4f9efb-795c-4253-de18-d7b2be471bb0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>label‰ of all</th>\n",
       "      <td>95</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total wrong</th>\n",
       "      <td>1134</td>\n",
       "      <td>300</td>\n",
       "      <td>571</td>\n",
       "      <td>89</td>\n",
       "      <td>799</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-&gt;N</th>\n",
       "      <td>850</td>\n",
       "      <td>219</td>\n",
       "      <td>257</td>\n",
       "      <td>85</td>\n",
       "      <td>438</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-&gt;P</th>\n",
       "      <td>284</td>\n",
       "      <td>81</td>\n",
       "      <td>314</td>\n",
       "      <td>4</td>\n",
       "      <td>361</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P-&gt;N %</th>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>45</td>\n",
       "      <td>95</td>\n",
       "      <td>54</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N-&gt;P %</th>\n",
       "      <td>25</td>\n",
       "      <td>27</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg len</th>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>38</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "label‰ of all     95            10       52       2      49              7\n",
       "total wrong     1134           300      571      89     799            235\n",
       "P->N             850           219      257      85     438            175\n",
       "N->P             284            81      314       4     361             60\n",
       "P->N %            74            73       45      95      54             74\n",
       "N->P %            25            27       54       4      45             25\n",
       "avg len           35            25       38      27      28             29"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "default_view": {},
   "name": "RCNN performance analysis.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
